<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Authors | MIRer</title>
    <link>/authors/</link>
      <atom:link href="/authors/index.xml" rel="self" type="application/rss+xml" />
    <description>Authors</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>/images/icon_hu25a3ac0bff28d67894e084ca1bc4b864_11852_512x512_fill_lanczos_center_2.png</url>
      <title>Authors</title>
      <link>/authors/</link>
    </image>
    
    <item>
      <title></title>
      <link>/authors/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/admin/</guid>
      <description>&lt;p&gt;MA Yinghao (马英浩) is an AI Music Ph.D. student at Centre for Digital Music (C4DM), School of EECS, Queen Mary University of London, supervised by Dr. Emmanouil Benetos, Dr. Chris Donahue (secondary), and Prof. Simon Dixon (independent assessor). &lt;!-- His research interests include machine learning (especially self-supervised learning, SSL) and signal processing for music information retrieval (MIR) and  multimodal learning. --&gt; 
He is one of the co-founders of the Multimodal Art Projection (&lt;a href=&#34;https://m-a-p.ai/&#34; target=&#34;_blank&#34;&gt;MAP&lt;/a&gt;) community.
Together with his colleague, he proposed an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), with more than 50k downloads on the &lt;a href=&#34;https://huggingface.co/m-a-p/&#34; target=&#34;_blank&#34;&gt;Huggingfac page&lt;/a&gt;, and established a Music Audio Representation Benchmark for universaL Evaluation (&lt;a href=&#34;https://marble-bm.sheffield.ac.uk/&#34; target=&#34;_blank&#34;&gt;MRABLE&lt;/a&gt;). 
He is also interested in music-related multimodality and developed &lt;a href=&#34;https://github.com/zihaod/MusiLingo&#34; target=&#34;_blank&#34;&gt;MusiLingo&lt;/a&gt;, a music captioning and query response model based on the alignment of single-modality pre-trained models.&lt;/p&gt;
&lt;p&gt;Besides, he was one of student conductors of Chinese Philharmonic Orchestra, 
Chinese Music Institute at Peking University (&lt;a href=&#34;https://www.facebook.com/Peking-University-Chinese-Music-Institute-cmipku-709151079161865/?ref=bookmarks&#34; target=&#34;_blank&#34;&gt;Facebook Page&lt;/a&gt;). 
He is also an advocate of charitable activities (see at &lt;a href=&#34;#experience&#34;&gt;other experience&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;He is now seeking for a summer internship position on SSL for MIR or music-related multimodality, in order to pave the way for a human understanding of music phenomenon. &lt;!--He is now applying for Graduate studies, in pursuit of his passion in exploring new things and innovating new ideas.--&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
